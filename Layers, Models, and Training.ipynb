{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68765efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631884a",
   "metadata": {},
   "source": [
    "## 1. Defining Custom Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f911e83",
   "metadata": {},
   "source": [
    "The fundamental data structure in neural networks is the layer. A Layer is an object that encapsulates some state (weights) and some computation (a forward pass). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40400671",
   "metadata": {},
   "source": [
    "`tf.keras.layers.Layer` is the base class of all Keras layers, and it inherits from `tf.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ee931",
   "metadata": {},
   "source": [
    "#### a)  Define a Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2393cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    # Adding **kwargs to support base Keras layer arguments\n",
    "    def __init__(self, in_features, out_features, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.w = tf.Variable(\n",
    "          tf.random.normal([in_features, out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f51326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         0.         0.62631154 0.        ]\n",
      " [3.1748524  0.21416539 1.6106186  1.5374866 ]\n",
      " [1.1436118  0.         2.6898258  0.        ]\n",
      " [1.4765915  0.         1.190513   0.44810957]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "simple_layer = MyDense(name=\"simple\", in_features=2, out_features=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((4,2))\n",
    "y = simple_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc483d54",
   "metadata": {},
   "source": [
    "#### b) Build Method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a64c5",
   "metadata": {},
   "source": [
    "It is often convenient to delay creating variables until the input shape is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac961342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f73dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2.138733   1.7557027 -4.5178404  0.7331276]\n",
      " [-1.3097725 -0.892485   2.8067265 -0.5892049]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "flexible_layer = MyDense(name=\"simple\", units=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = flexible_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d806f781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple/w:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.986195  ,  1.4475119 , -1.9436631 , -0.15155411],\n",
       "        [-0.5895405 , -0.07098993,  1.3356884 , -0.51903397]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this point we can inspect the variable\n",
    "\n",
    "flexible_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11081e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also call the variables by name\n",
    "\n",
    "flexible_layer.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2ab5c",
   "metadata": {},
   "source": [
    "#### c) Non-trainable weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818c5d9",
   "metadata": {},
   "source": [
    "By default, the variables in a layer are trainable, i.e. they will tracked by the Gradient Tape and will be updated during backpropagation. However, we can also specify certain weights to be non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27f0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w', trainable=True)\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b', trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6682423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the layer\n",
    "\n",
    "my_new_layer = MyDense(units=16)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = my_new_layer(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ad08cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 2\n",
      "non-trainable weights: 1\n",
      "\n",
      " trainable_weights: [<tf.Variable 'my_dense/w:0' shape=(2, 16) dtype=float32, numpy=\n",
      "array([[-0.7355088 ,  0.03686604,  1.0252248 ,  0.2510457 , -0.42978644,\n",
      "        -0.100762  ,  0.08433677, -0.6933368 ,  0.04402104, -0.72181284,\n",
      "        -0.77774155, -0.2849295 ,  0.11753464,  1.8421999 , -1.4103441 ,\n",
      "         0.01198501],\n",
      "       [ 1.2224822 ,  0.84527147,  2.0184705 ,  0.08366144, -0.6439218 ,\n",
      "        -0.5447391 ,  0.20705801,  0.50502086, -1.235562  ,  1.1550584 ,\n",
      "         0.6949036 ,  0.61891955,  1.8606344 ,  2.2450087 , -0.46066526,\n",
      "         1.5981655 ]], dtype=float32)>]\n",
      "\n",
      " non trainable_weights: [<tf.Variable 'my_dense/b:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights:\", len(my_new_layer.weights))\n",
    "print(\"non-trainable weights:\", len(my_new_layer.non_trainable_weights))\n",
    "\n",
    "\n",
    "# It's not included in the trainable weights:\n",
    "print(\"\\n trainable_weights:\", my_new_layer.trainable_weights)\n",
    "print(\"\\n non trainable_weights:\", my_new_layer.non_trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8aeef",
   "metadata": {},
   "source": [
    "#### d) training arg in call()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "105bf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(CustomDropout, self).__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e01b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tf.Tensor(\n",
      "[[ 0.6519984  -0.867141  ]\n",
      " [ 0.10383062 -1.5074784 ]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_training:  tf.Tensor(\n",
      "[[ 0.        -1.734282 ]\n",
      " [ 0.        -3.0149567]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_inference:  tf.Tensor(\n",
      "[[ 0.6519984  -0.867141  ]\n",
      " [ 0.10383062 -1.5074784 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dropuout = CustomDropout(rate=0.5)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "print('input: ', x)\n",
    "\n",
    "\n",
    "# During training\n",
    "output_during_training = dropuout(x, training=True)\n",
    "print('\\n output_during_training: ', output_during_training)\n",
    "\n",
    "\n",
    "# During inference\n",
    "output_during_inference = dropuout(x, training=False)\n",
    "print('\\n output_during_inference: ', output_during_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad32be",
   "metadata": {},
   "source": [
    "#### e) Recursively composible  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef3770",
   "metadata": {},
   "source": [
    "It also possible to compose a layer out of other layers. The outer layer will automatically track the weights of the inner layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3430e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 6\n",
      "trainable weights: 3\n",
      "y.shape:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Let's assume we are reusing the Linear class\n",
    "# with a `build` method that we defined above.\n",
    "\n",
    "\n",
    "class MLPBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.dense_1 = MyDense(32)\n",
    "        self.dense_2 = MyDense(32)\n",
    "        self.dense_3 = MyDense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return self.dense_3(x)\n",
    "\n",
    "\n",
    "mlp = MLPBlock()\n",
    "y = mlp(tf.ones(shape=(3, 64)))  # The first call to the `mlp` will create the weights\n",
    "print(\"weights:\", len(mlp.weights))\n",
    "print(\"trainable weights:\", len(mlp.trainable_weights))\n",
    "print(\"y.shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a134696",
   "metadata": {},
   "source": [
    "## 2. Defining Models: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb898c",
   "metadata": {},
   "source": [
    "Given a set of (either predefined or custom defined) layers, we can begin to start composing them into a DAG to define a model. A `tf.keras.Model` is similar to a `tf.keras.layers.Layer` except that models come with extra functionality that make them easy to train, evaluate, load, save, and even train on multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e6f1f",
   "metadata": {},
   "source": [
    "#### a) Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b20252",
   "metadata": {},
   "source": [
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90892fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two ways to define a sequential model:\n",
    "\n",
    "# 1. Either as a list of layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(16),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Or instantiate a Sequential Model and add layers by calling the .add() method on it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(16))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "189310ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now we can call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee53f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can call summary method to display the graph\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609806d",
   "metadata": {},
   "source": [
    "#### b) Functional API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e28fe3",
   "metadata": {},
   "source": [
    "The __Functional API__ is more flexible than Sequential, and specifically come in handy when the model has non-linear topology, shared layers and/or multiple inputs, outputs.\n",
    "\n",
    "First, lets redefine the above model in Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a77a9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(4,))\n",
    "\n",
    "x = tf.keras.layers.Dense(32)(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Dense(16)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"functional_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62392e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f740b",
   "metadata": {},
   "source": [
    "With Functional API, it's easy to define more complex topologies. Lets define a model with multiple inputs and outputs.\n",
    "\n",
    "Let's say we want a model that takes in a few weather data variables on any given day to predict temperature and humidity for the same day:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- Pressure\n",
    "- Precipitation\n",
    "- Clouds\n",
    "- Wind\n",
    "\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- Temperature\n",
    "- Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd907233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets build this model\n",
    "\n",
    "pressure_input = tf.keras.layers.Input(shape=(1,), name='pressure')\n",
    "precipitation_input = tf.keras.layers.Input(shape=(1,), name='precipitation')\n",
    "clouds_input = tf.keras.layers.Input(shape=(1,), name='clouds')\n",
    "wind_input = tf.keras.layers.Input(shape=(1,), name='wind')\n",
    "\n",
    "\n",
    "# Lets pass the pressure and precipitaion through a one stack of linear layers, and clouds and wind through another\n",
    "x = tf.keras.layers.concatenate([pressure_input, precipitation_input])\n",
    "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=16, activation='relu')(x)\n",
    "\n",
    "\n",
    "y = tf.keras.layers.concatenate([clouds_input, wind_input])\n",
    "y = tf.keras.layers.Dense(units=32, activation='relu')(y)\n",
    "y = tf.keras.layers.Dense(units=16, activation='relu')(y)\n",
    "\n",
    "\n",
    "# Lets merge the two branches and send through a few more layers\n",
    "z = tf.keras.layers.concatenate([x,y])\n",
    "z = tf.keras.layers.Dense(units=32, activation='relu')(z)\n",
    "z = tf.keras.layers.Dense(units=16, activation='relu')(z)\n",
    "\n",
    "# Finally split again into two outputs\n",
    "temperature = tf.keras.layers.Dense(units=1)(z)\n",
    "humidity = tf.keras.layers.Dense(units=1)(z)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[pressure_input, precipitation_input, clouds_input, wind_input], \n",
    "                       outputs=[temperature, humidity], name=\"multi_input_output_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1eeaa794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_input_output_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pressure (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "precipitation (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clouds (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wind (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2)            0           pressure[0][0]                   \n",
      "                                                                 precipitation[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           clouds[0][0]                     \n",
      "                                                                 wind[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           96          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 32)           96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 16)           528         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32)           0           dense_19[0][0]                   \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           1056        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 16)           528         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            17          dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1)            17          dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,866\n",
      "Trainable params: 2,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can print the summary but it might be difficult to visualize the graph\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deb92d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Luckily we can also plot the model\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d1a9b",
   "metadata": {},
   "source": [
    "#### c) Subclassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f948b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d251e92",
   "metadata": {},
   "source": [
    "## 3. Training: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04d592",
   "metadata": {},
   "source": [
    "#### a) Model.fit() method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aceac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc07378b",
   "metadata": {},
   "source": [
    "#### b) Customizing what happens in Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f356f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "996535a0",
   "metadata": {},
   "source": [
    "#### c) Training Loop from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff190d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
