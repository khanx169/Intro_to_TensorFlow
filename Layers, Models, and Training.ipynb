{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68765efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 13:24:28.893727: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631884a",
   "metadata": {},
   "source": [
    "## 1. Defining Custom Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f911e83",
   "metadata": {},
   "source": [
    "The fundamental data structure in neural networks is the layer. A Layer is an object that encapsulates some state (weights) and some computation (a forward pass). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40400671",
   "metadata": {},
   "source": [
    "`tf.keras.layers.Layer` is the base class of all Keras layers, and it inherits from `tf.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ee931",
   "metadata": {},
   "source": [
    "#### a)  Define a Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2393cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    # Adding **kwargs to support base Keras layer arguments\n",
    "    def __init__(self, in_features, out_features, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.w = tf.Variable(\n",
    "          tf.random.normal([in_features, out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f51326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.08653166 0.22966197 0.         1.044555  ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.10650903 0.        ]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "simple_layer = MyDense(name=\"simple\", in_features=2, out_features=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((4,2))\n",
    "y = simple_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc483d54",
   "metadata": {},
   "source": [
    "#### b) Build Method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a64c5",
   "metadata": {},
   "source": [
    "It is often convenient to delay creating variables until the input shape is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac961342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f73dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.2748123  -1.5116853  -1.4001874  -0.0745426 ]\n",
      " [ 2.074977   -1.9278336   0.12819308 -0.03711125]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "flexible_layer = MyDense(name=\"simple\", units=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = flexible_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d806f781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple/w:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.41965386, -0.60658777, -0.9533053 , -0.04176497],\n",
       "        [ 1.4916046 , -1.2819241 ,  0.56170076, -0.01024992]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this point we can inspect the variable\n",
    "\n",
    "flexible_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11081e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also call the variables by name\n",
    "\n",
    "flexible_layer.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2ab5c",
   "metadata": {},
   "source": [
    "#### c) Non-trainable weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818c5d9",
   "metadata": {},
   "source": [
    "By default, the variables in a layer are trainable, i.e. they will tracked by the Gradient Tape and will be updated during backpropagation. However, we can also specify certain weights to be non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27f0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w', trainable=True)\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b', trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6682423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the layer\n",
    "\n",
    "my_new_layer = MyDense(units=16)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = my_new_layer(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ad08cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 2\n",
      "non-trainable weights: 1\n",
      "\n",
      " trainable_weights: [<tf.Variable 'my_dense/w:0' shape=(2, 16) dtype=float32, numpy=\n",
      "array([[ 2.0357635 ,  0.30741778,  2.4273572 ,  0.64737064, -0.4964726 ,\n",
      "         1.5019722 ,  0.22642569, -1.2576973 ,  0.87131995,  0.77146757,\n",
      "        -0.6624955 , -0.05618246, -0.0533936 ,  0.33431035, -0.46557087,\n",
      "         0.31508303],\n",
      "       [ 0.60329384, -1.3193748 , -0.7733371 , -0.48306003, -0.47486687,\n",
      "        -0.08753338, -2.233232  ,  1.1275212 , -0.48400486, -0.7623914 ,\n",
      "        -0.04054663,  1.0673361 ,  0.3238585 , -1.5913419 ,  0.8597862 ,\n",
      "        -0.0042291 ]], dtype=float32)>]\n",
      "\n",
      " non trainable_weights: [<tf.Variable 'my_dense/b:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights:\", len(my_new_layer.weights))\n",
    "print(\"non-trainable weights:\", len(my_new_layer.non_trainable_weights))\n",
    "\n",
    "\n",
    "# It's not included in the trainable weights:\n",
    "print(\"\\n trainable_weights:\", my_new_layer.trainable_weights)\n",
    "print(\"\\n non trainable_weights:\", my_new_layer.non_trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8aeef",
   "metadata": {},
   "source": [
    "#### d) training arg in call()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "105bf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(CustomDropout, self).__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e01b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tf.Tensor(\n",
      "[[ 0.9176131  -1.6380713 ]\n",
      " [ 0.52651024  0.43497774]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_training:  tf.Tensor(\n",
      "[[ 0. -0.]\n",
      " [ 0.  0.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_inference:  tf.Tensor(\n",
      "[[ 0.9176131  -1.6380713 ]\n",
      " [ 0.52651024  0.43497774]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dropuout = CustomDropout(rate=0.5)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "print('input: ', x)\n",
    "\n",
    "\n",
    "# During training\n",
    "output_during_training = dropuout(x, training=True)\n",
    "print('\\n output_during_training: ', output_during_training)\n",
    "\n",
    "\n",
    "# During inference\n",
    "output_during_inference = dropuout(x, training=False)\n",
    "print('\\n output_during_inference: ', output_during_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad32be",
   "metadata": {},
   "source": [
    "#### e) Recursively composible  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef3770",
   "metadata": {},
   "source": [
    "It also possible to compose a layer out of other layers. The outer layer will automatically track the weights of the inner layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3430e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 6\n",
      "trainable weights: 3\n",
      "y.shape:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Let's assume we are reusing the Linear class\n",
    "# with a `build` method that we defined above.\n",
    "\n",
    "\n",
    "class MLPBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.dense_1 = MyDense(32)\n",
    "        self.dense_2 = MyDense(32)\n",
    "        self.dense_3 = MyDense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return self.dense_3(x)\n",
    "\n",
    "\n",
    "mlp = MLPBlock()\n",
    "y = mlp(tf.ones(shape=(3, 64)))  # The first call to the `mlp` will create the weights\n",
    "print(\"weights:\", len(mlp.weights))\n",
    "print(\"trainable weights:\", len(mlp.trainable_weights))\n",
    "print(\"y.shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a134696",
   "metadata": {},
   "source": [
    "## 2. Defining Models: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb898c",
   "metadata": {},
   "source": [
    "Given a set of (either predefined or custom defined) layers, we can begin to start composing them into a DAG to define a model. A `tf.keras.Model` is similar to a `tf.keras.layers.Layer` except that models come with extra functionality that make them easy to train, evaluate, load, save, and even train on multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e6f1f",
   "metadata": {},
   "source": [
    "#### a) Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b20252",
   "metadata": {},
   "source": [
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90892fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two ways to define a sequential model:\n",
    "\n",
    "# 1. Either as a list of layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(16),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Or instantiate a Sequential Model and add layers by calling the .add() method on it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(16))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "189310ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now we can call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee53f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can call summary method to display the graph\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609806d",
   "metadata": {},
   "source": [
    "#### b) Functional API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e28fe3",
   "metadata": {},
   "source": [
    "The __Functional API__ is more flexible than Sequential, and specifically come in handy when the model has non-linear topology, shared layers and/or multiple inputs, outputs.\n",
    "\n",
    "First, lets redefine the above model in Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a77a9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(4,))\n",
    "\n",
    "x = tf.keras.layers.Dense(32)(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Dense(16)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"functional_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62392e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f740b",
   "metadata": {},
   "source": [
    "With Functional API, it's easy to define more complex topologies. Lets define a model with multiple inputs and outputs.\n",
    "\n",
    "Let's say we want a model that takes in a few weather data variables on any given day to predict temperature and humidity for the same day:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- Pressure\n",
    "- Precipitation\n",
    "- Clouds\n",
    "- Wind\n",
    "\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- Temperature\n",
    "- Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd907233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets build this model\n",
    "\n",
    "pressure_input = tf.keras.layers.Input(shape=(1,), name='pressure')\n",
    "precipitation_input = tf.keras.layers.Input(shape=(1,), name='precipitation')\n",
    "clouds_input = tf.keras.layers.Input(shape=(1,), name='clouds')\n",
    "wind_input = tf.keras.layers.Input(shape=(1,), name='wind')\n",
    "\n",
    "\n",
    "# Lets pass the pressure and precipitaion through a one stack of linear layers, and clouds and wind through another\n",
    "x = tf.keras.layers.concatenate([pressure_input, precipitation_input])\n",
    "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=16, activation='relu')(x)\n",
    "\n",
    "\n",
    "y = tf.keras.layers.concatenate([clouds_input, wind_input])\n",
    "y = tf.keras.layers.Dense(units=32, activation='relu')(y)\n",
    "y = tf.keras.layers.Dense(units=16, activation='relu')(y)\n",
    "\n",
    "\n",
    "# Lets merge the two branches and send through a few more layers\n",
    "z = tf.keras.layers.concatenate([x,y])\n",
    "z = tf.keras.layers.Dense(units=32, activation='relu')(z)\n",
    "z = tf.keras.layers.Dense(units=16, activation='relu')(z)\n",
    "\n",
    "# Finally split again into two outputs\n",
    "temperature = tf.keras.layers.Dense(units=1, name='temperature')(z)\n",
    "humidity = tf.keras.layers.Dense(units=1, name='humidity')(z)\n",
    "\n",
    "\n",
    "multiple_inp_model = tf.keras.Model(inputs=[pressure_input, precipitation_input, clouds_input, wind_input], \n",
    "                       outputs=[temperature, humidity], name=\"multi_input_output_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eeaa794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_input_output_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pressure (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "precipitation (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clouds (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wind (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2)            0           pressure[0][0]                   \n",
      "                                                                 precipitation[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           clouds[0][0]                     \n",
      "                                                                 wind[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           96          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 16)           528         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32)           0           dense_10[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           1056        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           528         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "temperature (Dense)             (None, 1)            17          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "humidity (Dense)                (None, 1)            17          dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,866\n",
      "Trainable params: 2,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can print the summary but it might be difficult to visualize the graph\n",
    "multiple_inp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deb92d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Luckily we can also plot the model\n",
    "tf.keras.utils.plot_model(multiple_inp_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d1a9b",
   "metadata": {},
   "source": [
    "#### c) Subclassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c91f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        self.dense_1 = tf.keras.layers.Dense(32)\n",
    "        self.dense_2 = tf.keras.layers.Dense(16)\n",
    "        self.dense_3 = tf.keras.layers.Dense(1)\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.dense_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f460f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "model = FCN()\n",
    "\n",
    "\n",
    "# Call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd8cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fcn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             multiple                  160       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  17        \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               multiple                  0         \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d251e92",
   "metadata": {},
   "source": [
    "## 3. Training: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59662669",
   "metadata": {},
   "source": [
    "For this exercise, we will fix the model architecture (a small CNN) and train it on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3068e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "train_images, val_images = train_images[:50000], train_images[50000:]\n",
    "train_labels, val_labels = train_labels[:50000], train_labels[50000:]\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "val_labels = to_categorical(val_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b01d2911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "my_CNN = tf.keras.Model(inputs=Input, outputs=Output)\n",
    "my_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04d592",
   "metadata": {},
   "source": [
    "#### a) Model.fit() method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4528e",
   "metadata": {},
   "source": [
    "To use the built in methods `(Model.fit(), Model.evaluate(), Model.predict() `, we simply need to specify the\n",
    "- optimizer\n",
    "- loss\n",
    "- metrics\n",
    "\n",
    "and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56b655a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_CNN.compile(\n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    # Loss function to minimize\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a0938",
   "metadata": {},
   "source": [
    "The `.fit()` method will accept `numpy arrays`, `tf.data.Dataset` objects and `data generators`. Here we will input the MNIST data as a numpy array.\n",
    "\n",
    "The `.fit()` method can slice the data into batches, and will iterate over the entire dataset for a given number of epochs. Additionally, after each epoch it will evaluate on a hold-out validation set if specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f91d4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 13:25:06.588961: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-22 13:25:06.620405: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3783000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 0.2030 - categorical_accuracy: 0.9373 - val_loss: 0.0958 - val_categorical_accuracy: 0.9721\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 0.0562 - categorical_accuracy: 0.9825 - val_loss: 0.0510 - val_categorical_accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "history = my_CNN.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    validation_data=(val_images, val_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd1e6b",
   "metadata": {},
   "source": [
    "The returned history object holds a record of the loss and metric values recorded at the end of each epoch during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ed3a4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.202972874045372, 0.056160375475883484],\n",
       " 'categorical_accuracy': [0.9373000264167786, 0.9824600219726562],\n",
       " 'val_loss': [0.0957731083035469, 0.050980113446712494],\n",
       " 'val_categorical_accuracy': [0.972100019454956, 0.9850000143051147]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7bac2",
   "metadata": {},
   "source": [
    "After training, we can call the `evaaluate` or `predict` methods on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b0c4559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0415 - categorical_accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04154766723513603, 0.9861999750137329]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_CNN.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dce7c1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = my_CNN.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "324636e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa68b6e",
   "metadata": {},
   "source": [
    "###### What if there are multiple outputs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2529838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple_inp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edd13da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_inp_model.compile(\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    \n",
    "    # Loss function to minimize\n",
    "    loss = {\n",
    "        'temperature': tf.keras.losses.MeanSquaredError(),\n",
    "        'humidity': tf.keras.losses.CategoricalCrossentropy()\n",
    "    },\n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    metrics = {\n",
    "        'temperature': [tf.keras.metrics.MeanAbsoluteError(),],\n",
    "        'humidity': [tf.keras.metrics.CategoricalAccuracy(),]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07378b",
   "metadata": {},
   "source": [
    "#### b) Customizing what happens in Model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a8101",
   "metadata": {},
   "source": [
    "To customize what `fit()` does, we just need to override the `train_step(self, data)` method of the `Model` class.\n",
    "\n",
    "Let's do this with our simple CNN from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9159f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
    "\n",
    "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "accuracy_tracker = tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute our own loss\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, y_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Compute our own metrics\n",
    "        loss_tracker.update_state(loss)\n",
    "        accuracy_tracker.update_state(y, y_pred)\n",
    "        return {\"loss\": loss_tracker.result(), \"acc\": accuracy_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [loss_tracker, accuracy_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bd77ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the architecture\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reconstruct an instance of our CNN model\n",
    "my_new_CNN = CustomModel(inputs=Input, outputs=Output)\n",
    "\n",
    "# Now during compilation we don't need to pass loss or metrics\n",
    "my_new_CNN.compile(optimizer=\"adam\")\n",
    "\n",
    "# Print summary\n",
    "my_new_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a871b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 61s 77ms/step - loss: 0.2087 - acc: 0.8524\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 61s 77ms/step - loss: 0.0566 - acc: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffe9056eaf0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train \n",
    "my_new_CNN.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996535a0",
   "metadata": {},
   "source": [
    "#### c) Training Loop from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aeff190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "\n",
    "Input = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(Input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "Output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=Input, outputs=Output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1be387ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to simulate batches\n",
    "\n",
    "batch_size= 16\n",
    "\n",
    "train_images = train_images.reshape(-1, batch_size, 28,28,1)\n",
    "val_images = val_images.reshape(-1, batch_size, 28,28,1)\n",
    "test_images = test_images.reshape(-1, batch_size, 28,28,1)\n",
    "\n",
    "train_labels = train_labels.reshape(-1, batch_size, 10)\n",
    "val_labels = val_labels.reshape(-1, batch_size, 10)\n",
    "test_labels = test_labels.reshape(-1, batch_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e92019d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer, Loss functions and Metrics\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81c15833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 2.3106\n",
      "Seen so far: 16 samples\n",
      "Training loss (for one batch) at step 200: 0.2653\n",
      "Seen so far: 3216 samples\n",
      "Training loss (for one batch) at step 400: 0.0190\n",
      "Seen so far: 6416 samples\n",
      "Training loss (for one batch) at step 600: 0.1513\n",
      "Seen so far: 9616 samples\n",
      "Training loss (for one batch) at step 800: 0.1359\n",
      "Seen so far: 12816 samples\n",
      "Training loss (for one batch) at step 1000: 0.0313\n",
      "Seen so far: 16016 samples\n",
      "Training loss (for one batch) at step 1200: 0.0534\n",
      "Seen so far: 19216 samples\n",
      "Training loss (for one batch) at step 1400: 0.0873\n",
      "Seen so far: 22416 samples\n",
      "Training loss (for one batch) at step 1600: 0.1444\n",
      "Seen so far: 25616 samples\n",
      "Training loss (for one batch) at step 1800: 0.0709\n",
      "Seen so far: 28816 samples\n",
      "Training loss (for one batch) at step 2000: 0.0121\n",
      "Seen so far: 32016 samples\n",
      "Training loss (for one batch) at step 2200: 0.1196\n",
      "Seen so far: 35216 samples\n",
      "Training loss (for one batch) at step 2400: 0.2274\n",
      "Seen so far: 38416 samples\n",
      "Training loss (for one batch) at step 2600: 0.0593\n",
      "Seen so far: 41616 samples\n",
      "Training loss (for one batch) at step 2800: 0.0045\n",
      "Seen so far: 44816 samples\n",
      "Training loss (for one batch) at step 3000: 0.0526\n",
      "Seen so far: 48016 samples\n",
      "Training acc over epoch: 0.9545\n",
      "Validation acc: 0.9835\n",
      "Time taken: 107.32s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 16 samples\n",
      "Training loss (for one batch) at step 200: 0.0742\n",
      "Seen so far: 3216 samples\n",
      "Training loss (for one batch) at step 400: 0.0014\n",
      "Seen so far: 6416 samples\n",
      "Training loss (for one batch) at step 600: 0.0435\n",
      "Seen so far: 9616 samples\n",
      "Training loss (for one batch) at step 800: 0.0046\n",
      "Seen so far: 12816 samples\n",
      "Training loss (for one batch) at step 1000: 0.0051\n",
      "Seen so far: 16016 samples\n",
      "Training loss (for one batch) at step 1200: 0.0038\n",
      "Seen so far: 19216 samples\n",
      "Training loss (for one batch) at step 1400: 0.0372\n",
      "Seen so far: 22416 samples\n",
      "Training loss (for one batch) at step 1600: 0.1427\n",
      "Seen so far: 25616 samples\n",
      "Training loss (for one batch) at step 1800: 0.0249\n",
      "Seen so far: 28816 samples\n",
      "Training loss (for one batch) at step 2000: 0.0004\n",
      "Seen so far: 32016 samples\n",
      "Training loss (for one batch) at step 2200: 0.0637\n",
      "Seen so far: 35216 samples\n",
      "Training loss (for one batch) at step 2400: 0.2995\n",
      "Seen so far: 38416 samples\n",
      "Training loss (for one batch) at step 2600: 0.0082\n",
      "Seen so far: 41616 samples\n",
      "Training loss (for one batch) at step 2800: 0.0101\n",
      "Seen so far: 44816 samples\n",
      "Training loss (for one batch) at step 3000: 0.0024\n",
      "Seen so far: 48016 samples\n",
      "Training acc over epoch: 0.9854\n",
      "Validation acc: 0.9874\n",
      "Time taken: 107.12s\n"
     ]
    }
   ],
   "source": [
    "# Training Script\n",
    "\n",
    "import time\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Reinstantiate datasets (don't have to do this for data generators or tf.data)\n",
    "    train_dataset = zip(train_images, train_labels)\n",
    "    val_dataset = zip(val_images, val_labels)\n",
    "    test_dataset = zip(test_images, test_labels)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        \n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    \n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    \n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c1684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.3.1]",
   "language": "python",
   "name": "conda-env-opence-v1.3.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
