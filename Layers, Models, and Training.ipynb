{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68765efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631884a",
   "metadata": {},
   "source": [
    "## 1. Defining Custom Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f911e83",
   "metadata": {},
   "source": [
    "The fundamental data structure in neural networks is the layer. A Layer is an object that encapsulates some state (weights) and some computation (a forward pass). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40400671",
   "metadata": {},
   "source": [
    "`tf.keras.layers.Layer` is the base class of all Keras layers, and it inherits from `tf.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ee931",
   "metadata": {},
   "source": [
    "#### a)  Define a Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2393cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    # Adding **kwargs to support base Keras layer arguments\n",
    "    def __init__(self, in_features, out_features, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.w = tf.Variable(\n",
    "          tf.random.normal([in_features, out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f51326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.12239385 0.         0.         1.1331159 ]\n",
      " [0.         1.4213165  0.28176796 0.01418395]\n",
      " [0.22830437 0.         0.         0.        ]\n",
      " [0.         0.41254354 0.47291455 0.        ]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "simple_layer = MyDense(name=\"simple\", in_features=2, out_features=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((4,2))\n",
    "y = simple_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc483d54",
   "metadata": {},
   "source": [
    "#### b) Build Method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a64c5",
   "metadata": {},
   "source": [
    "It is often convenient to delay creating variables until the input shape is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac961342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f73dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.2818995   3.6266985  -2.1463177  -1.3724216 ]\n",
      " [-0.45315763 -0.60562986  1.2862213   0.23369679]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your layer\n",
    "\n",
    "flexible_layer = MyDense(name=\"simple\", units=4)\n",
    "\n",
    "\n",
    "# Call the layer on a sample input\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = flexible_layer(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d806f781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple/w:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.09635675,  1.4592559 ,  0.764034  , -0.54429656],\n",
       "        [ 0.88694566,  2.3231995 , -1.6301693 , -0.880391  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this point we can inspect the variable\n",
    "\n",
    "flexible_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11081e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple/b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also call the variables by name\n",
    "\n",
    "flexible_layer.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2ab5c",
   "metadata": {},
   "source": [
    "#### c) Non-trainable weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818c5d9",
   "metadata": {},
   "source": [
    "By default, the variables in a layer are trainable, i.e. they will tracked by the Gradient Tape and will be updated during backpropagation. However, we can also specify certain weights to be non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27f0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.units]), name='w', trainable=True)\n",
    "        self.b = tf.Variable(tf.zeros([self.units]), name='b', trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6682423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the layer\n",
    "\n",
    "my_new_layer = MyDense(units=16)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "y = my_new_layer(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ad08cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 2\n",
      "non-trainable weights: 1\n",
      "\n",
      " trainable_weights: [<tf.Variable 'my_dense/w:0' shape=(2, 16) dtype=float32, numpy=\n",
      "array([[ 1.2969841 ,  0.610474  , -1.5344253 ,  1.0515987 ,  0.23048133,\n",
      "        -0.45529392,  1.4825242 , -0.24479723,  0.37186486, -1.1000478 ,\n",
      "         0.47395763, -0.34441286,  1.3781023 , -0.566258  ,  0.8011622 ,\n",
      "        -1.2585021 ],\n",
      "       [-0.42209846,  1.3883487 ,  1.7076505 , -0.6812025 , -0.35678172,\n",
      "        -1.0544008 , -0.20595   ,  0.9043317 , -0.45903835,  0.8311017 ,\n",
      "        -0.313266  ,  1.6771985 , -0.1826686 ,  0.3008226 , -0.8782128 ,\n",
      "         1.1014637 ]], dtype=float32)>]\n",
      "\n",
      " non trainable_weights: [<tf.Variable 'my_dense/b:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights:\", len(my_new_layer.weights))\n",
    "print(\"non-trainable weights:\", len(my_new_layer.non_trainable_weights))\n",
    "\n",
    "\n",
    "# It's not included in the trainable weights:\n",
    "print(\"\\n trainable_weights:\", my_new_layer.trainable_weights)\n",
    "print(\"\\n non trainable_weights:\", my_new_layer.non_trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8aeef",
   "metadata": {},
   "source": [
    "#### d) training arg in call()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105bf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(CustomDropout, self).__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0e01b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tf.Tensor(\n",
      "[[-1.0439885   0.01639184]\n",
      " [-0.2634523  -1.0460414 ]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_training:  tf.Tensor(\n",
      "[[-2.087977    0.03278367]\n",
      " [-0.         -2.0920827 ]], shape=(2, 2), dtype=float32)\n",
      "\n",
      " output_during_inference:  tf.Tensor(\n",
      "[[-1.0439885   0.01639184]\n",
      " [-0.2634523  -1.0460414 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dropuout = CustomDropout(rate=0.5)\n",
    "\n",
    "x = tf.random.normal((2,2))\n",
    "print('input: ', x)\n",
    "\n",
    "\n",
    "# During training\n",
    "output_during_training = dropuout(x, training=True)\n",
    "print('\\n output_during_training: ', output_during_training)\n",
    "\n",
    "\n",
    "# During inference\n",
    "output_during_inference = dropuout(x, training=False)\n",
    "print('\\n output_during_inference: ', output_during_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad32be",
   "metadata": {},
   "source": [
    "#### e) Recursively composible  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef3770",
   "metadata": {},
   "source": [
    "It also possible to compose a layer out of other layers. The outer layer will automatically track the weights of the inner layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3430e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 6\n",
      "trainable weights: 3\n",
      "y.shape:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Let's assume we are reusing the Linear class\n",
    "# with a `build` method that we defined above.\n",
    "\n",
    "\n",
    "class MLPBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.dense_1 = MyDense(32)\n",
    "        self.dense_2 = MyDense(32)\n",
    "        self.dense_3 = MyDense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return self.dense_3(x)\n",
    "\n",
    "\n",
    "mlp = MLPBlock()\n",
    "y = mlp(tf.ones(shape=(3, 64)))  # The first call to the `mlp` will create the weights\n",
    "print(\"weights:\", len(mlp.weights))\n",
    "print(\"trainable weights:\", len(mlp.trainable_weights))\n",
    "print(\"y.shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a134696",
   "metadata": {},
   "source": [
    "## 2. Defining Models: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb898c",
   "metadata": {},
   "source": [
    "Given a set of (either predefined or custom defined) layers, we can begin to start composing them into a DAG to define a model. A `tf.keras.Model` is similar to a `tf.keras.layers.Layer` except that models come with extra functionality that make them easy to train, evaluate, load, save, and even train on multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e6f1f",
   "metadata": {},
   "source": [
    "#### a) Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b20252",
   "metadata": {},
   "source": [
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90892fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two ways to define a sequential model:\n",
    "\n",
    "# 1. Either as a list of layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(16),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Or instantiate a Sequential Model and add layers by calling the .add() method on it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(16))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "189310ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now we can call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee53f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can call summary method to display the graph\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609806d",
   "metadata": {},
   "source": [
    "#### b) Functional API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e28fe3",
   "metadata": {},
   "source": [
    "The __Functional API__ is more flexible than Sequential, and specifically come in handy when the model has non-linear topology, shared layers and/or multiple inputs, outputs.\n",
    "\n",
    "First, lets redefine the above model in Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a77a9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(4,))\n",
    "\n",
    "x = tf.keras.layers.Dense(32)(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Dense(16)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"functional_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62392e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f740b",
   "metadata": {},
   "source": [
    "With Functional API, it's easy to define more complex topologies. Lets define a model with multiple inputs and outputs.\n",
    "\n",
    "Let's say we want a model that takes in a few weather data variables on any given day to predict temperature and humidity for the same day:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- Pressure\n",
    "- Precipitation\n",
    "- Clouds\n",
    "- Wind\n",
    "\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- Temperature\n",
    "- Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd907233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets build this model\n",
    "\n",
    "pressure_input = tf.keras.layers.Input(shape=(1,), name='pressure')\n",
    "precipitation_input = tf.keras.layers.Input(shape=(1,), name='precipitation')\n",
    "clouds_input = tf.keras.layers.Input(shape=(1,), name='clouds')\n",
    "wind_input = tf.keras.layers.Input(shape=(1,), name='wind')\n",
    "\n",
    "\n",
    "# Lets pass the pressure and precipitaion through a one stack of linear layers, and clouds and wind through another\n",
    "x = tf.keras.layers.concatenate([pressure_input, precipitation_input])\n",
    "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=16, activation='relu')(x)\n",
    "\n",
    "\n",
    "y = tf.keras.layers.concatenate([clouds_input, wind_input])\n",
    "y = tf.keras.layers.Dense(units=32, activation='relu')(y)\n",
    "y = tf.keras.layers.Dense(units=16, activation='relu')(y)\n",
    "\n",
    "\n",
    "# Lets merge the two branches and send through a few more layers\n",
    "z = tf.keras.layers.concatenate([x,y])\n",
    "z = tf.keras.layers.Dense(units=32, activation='relu')(z)\n",
    "z = tf.keras.layers.Dense(units=16, activation='relu')(z)\n",
    "\n",
    "# Finally split again into two outputs\n",
    "temperature = tf.keras.layers.Dense(units=1)(z)\n",
    "humidity = tf.keras.layers.Dense(units=1)(z)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[pressure_input, precipitation_input, clouds_input, wind_input], \n",
    "                       outputs=[temperature, humidity], name=\"multi_input_output_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eeaa794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_input_output_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pressure (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "precipitation (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clouds (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wind (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2)            0           pressure[0][0]                   \n",
      "                                                                 precipitation[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           clouds[0][0]                     \n",
      "                                                                 wind[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           96          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 16)           528         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32)           0           dense_10[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           1056        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           528         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            17          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            17          dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,866\n",
      "Trainable params: 2,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can print the summary but it might be difficult to visualize the graph\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deb92d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Luckily we can also plot the model\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d1a9b",
   "metadata": {},
   "source": [
    "#### c) Subclassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c91f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        self.dense_1 = tf.keras.layers.Dense(32)\n",
    "        self.dense_2 = tf.keras.layers.Dense(16)\n",
    "        self.dense_3 = tf.keras.layers.Dense(1)\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.dense_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbda00cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "model = FCN()\n",
    "\n",
    "\n",
    "# Call the model on an Input Tensor\n",
    "x = tf.ones((16, 4))\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42857349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fcn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             multiple                  160       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  17        \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               multiple                  0         \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d251e92",
   "metadata": {},
   "source": [
    "## 3. Training: Three Levels of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acaba9e",
   "metadata": {},
   "source": [
    "For this exercise, we will fix the model architecture (a small CNN) and train it on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ef47c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "train_images, val_images = train_images[:50000], train_images[50000:]\n",
    "train_labels, val_labels = train_labels[:50000], train_labels[50000:]\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "val_labels = to_categorical(val_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6de19d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04d592",
   "metadata": {},
   "source": [
    "#### a) Model.fit() method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f5f62",
   "metadata": {},
   "source": [
    "To use the built in methods `(Model.fit(), Model.evaluate(), Model.predict() `, we simply need to specify the\n",
    "- optimizer\n",
    "- loss\n",
    "- metrics\n",
    "\n",
    "and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e837fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    # Loss function to minimize\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4a9ca1",
   "metadata": {},
   "source": [
    "The `.fit()` method will accept `numpy arrays`, `tf.data.Dataset` objects and `data generators`. Here we will input the MNIST data as a numpy array.\n",
    "\n",
    "The `.fit()` method can slice the data into batches, and will iterate over the entire dataset for a given number of epochs. Additionally, after each epoch it will evaluate on a hold-out validation set if specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbcf44c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 64s 81ms/step - loss: 0.1972 - categorical_accuracy: 0.9392 - val_loss: 0.0705 - val_categorical_accuracy: 0.9803\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 63s 81ms/step - loss: 0.0543 - categorical_accuracy: 0.9830 - val_loss: 0.0510 - val_categorical_accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    validation_data=(val_images, val_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8be155",
   "metadata": {},
   "source": [
    "The returned history object holds a record of the loss and metric values recorded at the end of each epoch during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed174ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.19717292487621307, 0.054348211735486984],\n",
       " 'categorical_accuracy': [0.9392399787902832, 0.983020007610321],\n",
       " 'val_loss': [0.07050801813602448, 0.05096294358372688],\n",
       " 'val_categorical_accuracy': [0.9803000092506409, 0.9854000210762024]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169ba456",
   "metadata": {},
   "source": [
    "After training, we can call the `evaaluate` or `predict` methods on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f07fb570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0418 - categorical_accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04175985977053642, 0.986299991607666]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23b7e230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06d28538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07378b",
   "metadata": {},
   "source": [
    "#### b) Customizing what happens in Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f356f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "996535a0",
   "metadata": {},
   "source": [
    "#### c) Training Loop from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff190d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.3.1]",
   "language": "python",
   "name": "conda-env-opence-v1.3.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
